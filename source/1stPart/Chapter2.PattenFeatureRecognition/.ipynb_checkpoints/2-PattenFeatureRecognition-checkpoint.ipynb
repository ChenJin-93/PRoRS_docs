{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-07T22:38:38.820584Z",
     "start_time": "2017-09-07T22:38:38.813574Z"
    }
   },
   "source": [
    "# 2.1 模式特征分类概述\n",
    "\n",
    "## 2.1.1 数学描述\n",
    "\n",
    " 问题：给定一组有类别标记的训练样本集𝐷 = {x1,…, xN} 或 𝐷 = {(x1,c1) ,…, (xN,cN)}<br>\n",
    " \n",
    " 如何使用一个算法给独立同分布的新观测样本x 分配准确的类别？<br>\n",
    "\n",
    " 解法：学习一个最优分类器或其参数（损失函数𝐿 𝛼 𝑦 , 𝑐 、分类规则𝑧 = 𝛼 𝑦 和判别函数𝑦 = 𝑓(𝑥) ），以极小化类别分配的风险：<br>\n",
    " \n",
    "![](Picture/figure_2-0.png)\n",
    "\n",
    "## 2.1.2 贝叶斯决策论\n",
    "\n",
    " 贝叶斯决策论（Bayesian decision theory）是在概率框架下实施决策的基本方法。<br>\n",
    " \n",
    " 在分类问题情况中，在所有相关概率都已知的理想情形下，贝叶斯决策就是寻找一个判定准则𝛼∗以最小化总体风险。\n",
    " \n",
    "![](Picture/figure_2-01.png)\n",
    "\n",
    "## 2.1.3 分类过程\n",
    "\n",
    " 最近邻法分类： 两类样本最近距离  + min(距离) <br>\n",
    " \n",
    " 线性判别分析:  变换后的值      + 与阈值的大小关系 <br>\n",
    " \n",
    " 朴素贝叶斯  ： 后验概率       + max(概率) <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 实验要求\n",
    "\n",
    "（1）利用所有训练样本以缺省参数学习分类器参数。<br>\n",
    "\n",
    "（2）随机选取离散化特征空间中的每个点（256 * 256个点）进行分类（2次）（通过进度条展示渐变过程）。<br>\n",
    "\n",
    "（3）绘制离散化的特征空间每个点分别是正类、负类的判别依据。<br>\n",
    "\n",
    "（4）绘制离散化的特征空间每个点基于选择规则的选择后的判别依据。<br> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 思考探索\n",
    "\n",
    "（1）对比不同分类器结果的差异，为什么？<br>\n",
    "\n",
    "（2）对比同一分类器两次结果的差异，回答为什么？<br>\n",
    "\n",
    "（3）分类器是什么？（映射函数？分类规则？分类边界？空间剖分？）<br>\n",
    "\n",
    "（4）如何构建分类器？（知识、学习？）<br>\n",
    "\n",
    "（5）机器学习的目标是什么？分类器学习学什么？什么是好的分类器？（错误率低、误差小）<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 案例展示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4.1 示例数据集\n",
    "示例数据集以Jupyter Notebook为基本工具。每个特征的取值范围为[0,255]，橙色表示+1类样本；蓝色表示-1类样本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）数据集一：\n",
    "```python\n",
    "    from sklearn import datasets\n",
    "    X,Y=datasets.make_blobs(n_samples=n, centers=2, n_features=2, cluster_std=2, random_state=1)\n",
    "    cm_bright = ListedColormap(['Blue', 'Orange'])\n",
    "    plt.scatter(X[:,0], X[:,1], s=1, c=Y, cmap=cm_bright)\n",
    "```  \n",
    "![](Picture/figure_1-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-07T22:52:10.487734Z",
     "start_time": "2017-09-07T22:52:10.463717Z"
    }
   },
   "source": [
    "（2）数据集二：\n",
    "```python\n",
    "    x= np.random.rand(n, 2); X=255*x\n",
    "    Y=[]\n",
    "    for i in range(0, n): \n",
    "        if (X[:,0][i]<=128 and X[:,1][i]<=128) or (X[:,0][i]>128 and X[:,1][i]>128):\n",
    "        Y.append(-1)\n",
    "        else:\n",
    "        Y.append(1)\n",
    "```       \n",
    "![](Picture/figure_1-2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）数据集三：\n",
    "```python\n",
    "    x,y= datasets.make_circles(n_samples=n, factor=0.05, noise=.2)\n",
    "```\n",
    "![](Picture/figure_1-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（4）数据集四：\n",
    "```python\n",
    "    t = 1 * np.pi * (0 + 4 * np.random.rand(1, n))\n",
    "    x0 = -t * np.cos(t); x2 = t * np.cos(t); x=np.concatenate((x0, x2), axis=1);\n",
    "    y0 = -t * np.sin(t); y2 = t * np.sin(t); y=np.concatenate((y0, y2), axis=1);\n",
    "    X = np.concatenate((x, y));\n",
    "    X += .3 * np.random.randn(2, 2*n);X = X.T;\n",
    "    X=255*MaxMinNormalization(X);\n",
    "    cs1=-1*np.ones(n); cs2=np.zeros(n); \n",
    "    Y=np.concatenate((cs1, cs2));\n",
    "```\n",
    "![](Picture/figure_1-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.4.2 模式分类   \n",
    "\n",
    "（1）离散化特征空间，当测试点数量增加，分类结果是否有差异？\n",
    "\n",
    "![](Picture/figure_2-1.png)\n",
    "\n",
    "利用所有训练样本以缺省参数学习分类器参数。<br>\n",
    "随机选取离散化特征空间中的每个点（256 * 256个点）进行分类。<br>\n",
    "图中第一列为不同数据集，第二到第五列分别代表从测试占整个特征空间的比例（0.01、0.05、0.1、1）。<br>\n",
    "当特征空间中用于测试的点数逐渐增加，可观察到在同种分类方法下（最邻近分类）的分类结果并无差异。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）同种分类器，对不同数据集进行两次分类的分类结果是否有差异？\n",
    "\n",
    "![](Picture/figure_2-2.png)\n",
    "\n",
    "图中第一列为不同数据集，第二到第三列分别为第一次分类结果和第二次分类结果。<br>\n",
    "从图中结果可看出同种分类器下，两次分类的结果也并无差异。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）不同分类器，对不同数据集进行分类的分类结果会有什么样的差异？\n",
    "\n",
    "![](Picture/figure_2-30.png)\n",
    "\n",
    "图中第一列为不同数据集，第二到第五列分别为不同分类器（线性判别，高斯朴素贝叶斯，二次判别，最邻近方法）的分类结果。<br>\n",
    "从图中结果可看出不同分类器下，特征空间中的分类结果存在明显差异。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（4）为什么不同分类器，分类结果会有差异？\n",
    "\n",
    "KNN：记住所有的训练样本，计算每个测试点到每个类别的所有训练点的距离，记录一个最近距离，对应的训练点类别，即是测试点的类别。<br>\n",
    "\n",
    "LDA：如果训练数据集的协方差矩阵一致，训练数据投影到一个维度上，得到决策边界，计算所有测试点到决策边界的距离，找出一个判断阈值，进而将所有测试点分类。<br>\n",
    "\n",
    "QDA：如果训练数据集的协方差矩阵不一致，得到的决策面是一个二次面。<br>\n",
    "\n",
    "GNB：根据训练集来估计类先验概率和每个特征的条件概率，然后利用训练出的模型，计算每个样本点的后验概率，求取最大后验概率，其对应的类别就是测试点的类别。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（5）分类器是什么？（映射函数？分类规则？分类边界？空间剖分？）\n",
    "\n",
    "当分类器的类型、参数给定了之后，分类器就是对特征空间的剖分。<br>\n",
    "同一分类器，测试点数量增加、两次分类的结果都是相同的。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4.3 分类过程\n",
    "\n",
    "（1）最邻近分类：KNeighborsClassifier\n",
    "\n",
    "```python\n",
    "    from sklearn.neighbors import  KNeighborsClassifier\n",
    "    clf =KNeighborsClassifier()\n",
    "    clf.fit(X, Y)\n",
    "    P=meshgrid()\n",
    "    y=clf.predict(P)\n",
    "    cm_bright = ListedColormap(['Blue', 'Orange'])\n",
    "    plt.scatter(P[:,0], P[:,1], c=y, cmap=cm_bright)\n",
    "    \n",
    "    判别依据：dist=clf.kneighbors(P)[0]\n",
    "    kneighbors(X=None, n_neighbors=None, return_distance=True)\n",
    "    Returns indices of and distances to the neighbors of each point\n",
    "```   \n",
    "![](Picture/figure_3-1.png)\n",
    "\n",
    "图中第二列为不同数据集的最邻近分类结果。<br>\n",
    "第三列为测试样本中相对于正类每个点到训练样本点的最邻近距离。<br>\n",
    "第四列为测试样本中相对与负类每个点到训练样本点的最邻近距离。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）线性判别分析：LDA\n",
    "```python\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "    clf =LinearDiscriminantAnalysis()\n",
    "   \n",
    "    判别依据：df=clf.decision_function(X) \n",
    "```\n",
    "![](Picture/figure_3-2.png)\n",
    "    \n",
    "图中第二列为不同数据集的线性判别结果。<br>\n",
    "第三列为测试样本中每个点到分类边界的距离。<br>\n",
    "距离为正则分类为正类；距离为负则分类为负类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）朴素贝叶斯：naive_bayes.GaussianNB\n",
    "```python\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    clf =GaussianNB()\n",
    "    clf.fit(X,Y)\n",
    "    y=clf.predict(P)\n",
    "    \n",
    "    判别依据：predict_proba(X)\n",
    "    Returns the probability of the samples for each class in the model. \n",
    "    The columns correspond to the classes in sorted order, as they appear in the attribute classes.\n",
    "```\n",
    "![](Picture/figure_3-3.png)\n",
    "\n",
    "图中第二列为不同数据集的高斯朴素贝叶斯的分类结果。<br>\n",
    "第三列为测试样本中每个点相对于正类的概率。<br> \n",
    "第四列为测试样本中每个点相对于负类的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（4）为什么naive_bayes.GaussianNB在不同数据集分类效果不同？<br>\n",
    "\n",
    "两类数据集看作两个服从高斯分布的数据集：<br>\n",
    "当两类数据集的高分分布协方差大致相同，高斯朴素贝叶斯分类边界呈现直线。<br>\n",
    "当两类数据集的高斯分布协方差不同，此时分类边界会偏向某一类数据集的均值中心。\n",
    "    \n",
    "![](Picture/figure_3-4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
