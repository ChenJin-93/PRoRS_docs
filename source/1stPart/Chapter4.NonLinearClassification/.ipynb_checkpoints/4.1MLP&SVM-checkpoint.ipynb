{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 算法原理\n",
    "\n",
    "## 4.1.1 神经网络的误差向后传递过程\n",
    "\n",
    "多层感知器(MLP) 是一种监督学习算法，通过在数据集上训练来学习函数 f(\\cdot): R^m \\rightarrow R^o，其中 m 是输入的维数，o 是输出的维数。 给定一组特征 X = {x_1, x_2, ..., x_m} 和标签 y ，它可以学习用于分类或回归的非线性函数。 与逻辑回归不同的是，在输入层和输出层之间，可以有一个或多个非线性层，称为隐藏层。\n",
    "\n",
    "最左层的输入层由一组代表输入特征的神经元 \\{x_i | x_1, x_2, ..., x_m\\} 组成。 每个隐藏层中的神经元将前一层的值进行加权线性求和转换 w_1x_1 + w_2x_2 + ... + w_mx_m ，再通过非线性激活函数 g(\\cdot):R \\rightarrow R - 比如双曲正切函数 tanh 。 输出层接收到的值是最后一个隐藏层的输出经过变换而来的。\n",
    "\n",
    "多层感知器的优点:\n",
    "\n",
    "可以学习得到非线性模型。\n",
    "使用``partial_fit`` 可以学习得到实时模型(在线学习)。\n",
    "多层感知器(MLP)的缺点:\n",
    "\n",
    "具有隐藏层的 MLP 具有非凸的损失函数，它有不止一个的局部最小值。 因此不同的随机权重初始化会导致不同的验证集准确率。\n",
    "MLP 需要调试一些超参数，例如隐藏层神经元的数量、层数和迭代轮数。\n",
    "MLP 对特征归一化很敏感.\n",
    "\n",
    "## 4.1.2 边界极大化\n",
    "\n",
    "支持向量机的优势在于:\n",
    "\n",
    "在高维空间中非常高效.\n",
    "即使在数据维度比样本数量大的情况下仍然有效.\n",
    "在决策函数（称为支持向量）中使用训练集的子集,因此它也是高效利用内存的.\n",
    "通用性: 不同的核函数 核函数 与特定的决策函数一一对应.常见的 kernel 已\n",
    "经提供,也可以指定定制的内核.\n",
    "\n",
    "支持向量机的缺点包括:\n",
    "\n",
    "如果特征数量比样本数量大得多,在选择核函数 核函数 时要避免过拟合,\n",
    "而且正则化项是非常重要的.\n",
    "\n",
    "支持向量机不直接提供概率估计,这些都是使用昂贵的五次交叉验算计算的. (详情见 Scores and probabilities, 在下文中).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
